{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rohah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: google-api-python-client in c:\\users\\rohah\\anaconda3\\envs\\jarvis\\lib\\site-packages (1.7.11)\n",
      "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in c:\\users\\rohah\\anaconda3\\envs\\jarvis\\lib\\site-packages (from google-api-python-client) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in c:\\users\\rohah\\anaconda3\\envs\\jarvis\\lib\\site-packages (from google-api-python-client) (0.14.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in c:\\users\\rohah\\anaconda3\\envs\\jarvis\\lib\\site-packages (from google-api-python-client) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in c:\\users\\rohah\\anaconda3\\envs\\jarvis\\lib\\site-packages (from google-api-python-client) (0.0.3)\n",
      "Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in c:\\users\\rohah\\anaconda3\\envs\\jarvis\\lib\\site-packages (from google-api-python-client) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in c:\\users\\rohah\\anaconda3\\envs\\jarvis\\lib\\site-packages (from google-auth>=1.4.1->google-api-python-client) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in c:\\users\\rohah\\anaconda3\\envs\\jarvis\\lib\\site-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.7)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=40.3.0 in c:\\users\\rohah\\anaconda3\\envs\\jarvis\\lib\\site-packages (from google-auth>=1.4.1->google-api-python-client) (41.6.0.post20191030)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in c:\\users\\rohah\\anaconda3\\envs\\jarvis\\lib\\site-packages (from google-auth>=1.4.1->google-api-python-client) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in c:\\users\\rohah\\anaconda3\\envs\\jarvis\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'discovery' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-aee087df34c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhttp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMediaIoBaseDownload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mDRIVE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscovery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'drive'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'v3'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhttp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauthorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHttp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# if you get the shareable link, the link contains this id, replace the file_id below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfile_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'1Vf8aByqXQwTVmxxs5jKenvAXaxSF6TsH'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'discovery' is not defined"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "DRIVE = discovery.build('drive', 'v3', http=creds.authorize(Http()))\n",
    "# if you get the shareable link, the link contains this id, replace the file_id below\n",
    "file_id = '1Vf8aByqXQwTVmxxs5jKenvAXaxSF6TsH'\n",
    "request = DRIVE.files().get_media(fileId=file_id)\n",
    "# replace the filename and extension in the first field below\n",
    "fh = io.FileIO('wiki-news-300d-1M.vec', mode='w')\n",
    "downloader = MediaIoBaseDownload(fh, request)\n",
    "done = False\n",
    "while done is False:\n",
    "    status, done = downloader.next_chunk()\n",
    "    print(\"Download %d%%.\" % int(status.progress() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from httplib2 import Http\n",
    "import oauth2client\n",
    "from oauth2client import file, client, tools\n",
    "obj = lambda: None\n",
    "lmao = {\"auth_host_name\":'localhost', 'noauth_local_webserver':'store_true', 'auth_host_port':[8080, 8090], 'logging_level':'ERROR'}\n",
    "for k, v in lmao.items():\n",
    "    setattr(obj, k, v)\n",
    "    \n",
    "# authorization boilerplate code\n",
    "SCOPES = 'https://www.googleapis.com/auth/drive.readonly'\n",
    "store = file.Storage('token.json')\n",
    "creds = store.get()\n",
    "# The following will give you a link if token.json does not exist, the link allows the user to give this app permission\n",
    "if not creds or creds.invalid:\n",
    "    flow = client.flow_from_clientsecrets('client_id.json', SCOPES)\n",
    "    creds = tools.run_flow(flow, store, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rand\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim  \n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D \n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "import os, re, csv, math, codecs\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(0)\n",
    "\n",
    "MAX_NB_WORDS = 100000\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['.', ',', '\"', \"'\", ':', ';', '(', ')', '[', ']', '{', '}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "232101it [00:29, 7800.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 232101 word vectors\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = codecs.open('./wiki-news-300d-1M.vec', encoding='utf-8')\n",
    "for line in tqdm(f):\n",
    "    values = line.rstrip().rsplit(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('found %s word vectors' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitIntoStem(message):\n",
    "    return [removeNumeric(stripEmoji(singleCharacterRemove(removePunctuation\n",
    "                                                           (removeHyperlinks\n",
    "                                                            (removeHashtags\n",
    "                                                             (removeUsernames\n",
    "                                                              (stemWord(word)))))))) for word in message.split()]\n",
    "def stemWord(tweet):\n",
    "    return tweet.lower()\n",
    "\n",
    "def removeUsernames(tweet):\n",
    "    return re.sub('@[^\\s]+', '', tweet)\n",
    "\n",
    "def removeHashtags(tweet):\n",
    "    return re.sub(r'#[^\\s]+', '', tweet)\n",
    "\n",
    "def removeHyperlinks(tweet):\n",
    "    return re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', '', tweet)\n",
    "\n",
    "def removeNumeric(value):\n",
    "    blist2 = [item for item in value if not item.isdigit()]\n",
    "    blist3 = \"\".join(blist2)\n",
    "    return blist3\n",
    "\n",
    "def removePunctuation(tweet):\n",
    "\n",
    "    return re.sub(r'[^\\w\\s]','',tweet)\n",
    "\n",
    "def singleCharacterRemove(tweet):\n",
    "    return re.sub(r'(?:^| )\\w(?:$| )', ' ', tweet)\n",
    "\n",
    "def stripEmoji(text):\n",
    "\n",
    "    RE_EMOJI = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
    "    return RE_EMOJI.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('./tweets.csv', sep=',', header=0)\n",
    "tweet_list = tweets_df['tweet'].tolist()\n",
    "# label_list = tweets_df['Label'].tolist()\n",
    "# one_hot_labels = keras.utils.to_categorical(label_list, num_classes=4)\n",
    "label_names = [\"business\", \"entertainment\", \"health\", \"politics\"]\n",
    "labels = tweets_df[label_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1096/1096 [00:00<00:00, 8791.56it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_list = []\n",
    "for sentence in tqdm(tweet_list):\n",
    "    tokens = \" \".join(splitIntoStem(sentence)).split()\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    processed_list.append(\" \".join(filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"tweet\"] = processed_list\n",
    "df['doc_len'] = df['tweet'].apply(lambda words: len(words.split(\" \")))\n",
    "max_seq_len = np.round(df['doc_len'].mean() + df['doc_len'].std()).astype(int)\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(processed_list, one_hot_labels, test_size=0.35)\n",
    "x_train, x_test, y_train, y_test = train_test_split(processed_list, labels, test_size=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary size:  4132\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train + x_test)\n",
    "word_seq_train = tokenizer.texts_to_sequences(x_train)\n",
    "word_seq_test = tokenizer.texts_to_sequences(x_test)\n",
    "word_index = tokenizer.word_index\n",
    "print(\"dictionary size: \", len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  9,  7, ..., 16,  8,  5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = [len(tokens) for tokens in word_seq_train + word_seq_test]\n",
    "num_tokens = np.array(num_tokens)\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_seq_train = sequence.pad_sequences(word_seq_train, maxlen=max_seq_len)\n",
    "word_seq_test = sequence.pad_sequences(word_seq_test, maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_seq_test = word_seq_test[:-1]\n",
    "y_test = y_test[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training params\n",
    "batch_size = 256\n",
    "num_epochs = 8 \n",
    "\n",
    "#model parameters\n",
    "num_filters = 64 \n",
    "embed_dim = 300 \n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
    "embedding_matrix2 = np.zeros((nb_words, embed_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of null word embeddings: 601\n",
      "sample words not found:  ['modis' 'ptsd' 'brzezinski' 'infowars' 'aamir' 'nyu' 'humantohuman'\n",
      " 'assange' 'johansson' 'baumol']\n"
     ]
    }
   ],
   "source": [
    "words_not_found = []\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        words_not_found.append(word)\n",
    "print('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
    "print(\"sample words not found: \", np.random.choice(words_not_found, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in word_index.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = word_vectors[word]\n",
    "        embedding_matrix2[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        embedding_matrix2[i]=np.random.normal(0,np.sqrt(0.25),embed_dim)\n",
    "\n",
    "del(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_seq_len, trainable=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(num_filters, 5, padding='same', activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(num_filters, 5, activation='relu', padding='same'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(nb_words, embed_dim, weights=[embedding_matrix2], input_length=max_seq_len, trainable=True))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Conv1D(num_filters, 5, padding='same', activation='relu', strides=1))\n",
    "model2.add(MaxPooling1D(2))\n",
    "model2.add(Conv1D(num_filters, 5, activation='relu', padding='same'))\n",
    "model2.add(GlobalMaxPooling1D())\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model2.add(Dense(4, activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(word_seq_train, y_train, batch_size = batch_size, epochs = num_epochs, shuffle = True, validation_data = (word_seq_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(word_seq_train, y_train, batch_size = batch_size, epochs = num_epochs, shuffle = True, validation_data = (word_seq_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(word_seq_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(word_seq_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = history.history['loss']\n",
    "val_loss1 = history.history['val_loss']\n",
    "acc1 = history.history['acc']\n",
    "val_acc1 = history.history['val_acc']\n",
    "loss2 = history2.history['loss']\n",
    "val_loss2 = history2.history['val_loss']\n",
    "acc2 = history2.history['acc']\n",
    "val_acc2 = history2.history['val_acc']\n",
    "\n",
    "epochs = range(1, len(loss1) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, loss1, color='red', label='Training loss')\n",
    "plt.plot(epochs, val_loss1, color='green', label='Validation loss')\n",
    "plt.title('Training and validation loss (fasttext)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc1, color='red', label='Training acc')\n",
    "plt.plot(epochs, val_acc1, color='green', label='Validation acc')\n",
    "plt.title('Training and validation accuracy (fasttext)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, loss2, color='red', label='Training loss')\n",
    "plt.plot(epochs, val_loss2, color='green', label='Validation loss')\n",
    "plt.title('Training and validation loss (skipgram)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc2, color='red', label='Training acc')\n",
    "plt.plot(epochs, val_acc2, color='green', label='Validation acc')\n",
    "plt.title('Training and validation accuracy (skipgram)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc1, color='red', label='Fasttext acc')\n",
    "plt.plot(epochs, acc2, color='green', label='Skipgram acc')\n",
    "plt.title('Training Accuracy fasttext & skipgram')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, val_acc1, color='red', label='Fasttext val_acc')\n",
    "plt.plot(epochs, val_acc2, color='green', label='Skipgram val_acc')\n",
    "plt.title('Validating Accuracy fasttext & skipgram')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, loss1, color='red', label='Fasttext loss')\n",
    "plt.plot(epochs, loss2, color='green', label='Skipgram loss')\n",
    "plt.title('Training Loss fasttext & skipgram')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, val_loss1, color='red', label='Fasttext val_loss')\n",
    "plt.plot(epochs, val_loss2, color='green', label='Skipgram val_loss')\n",
    "plt.title('Validating Loss fasttext & skipgram')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Embedding(nb_words, embed_dim, weights=[embedding_matrix2], input_length=max_seq_len, trainable=True))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Conv1D(num_filters, 5, padding='same', activation='relu', strides=1))\n",
    "model3.add(MaxPooling1D(2))\n",
    "model3.add(Conv1D(num_filters, 5, activation='relu', padding='same'))\n",
    "model3.add(MaxPooling1D(2))\n",
    "model3.add(Conv1D(num_filters, 5, activation='relu', padding='same'))\n",
    "model3.add(GlobalMaxPooling1D())\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model3.add(Dense(4, activation='softmax'))\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = model3.fit(word_seq_train, y_train, batch_size = batch_size, epochs = num_epochs, shuffle = True, validation_data = (word_seq_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.evaluate(word_seq_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss3 = history3.history['loss']\n",
    "val_loss3 = history3.history['val_loss']\n",
    "acc3 = history3.history['acc']\n",
    "val_acc3 = history3.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc2, color='red', label='Skipgram 2-CNN acc')\n",
    "plt.plot(epochs, acc3, color='green', label='Skipgram 3-CNN acc')\n",
    "plt.title('Training Accuracy skipgram CNN(2 Layers, 3 Layers)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, val_acc2, color='red', label='Skipgram CNN-2 val_acc')\n",
    "plt.plot(epochs, val_acc3, color='green', label='Skipgram CNN-3 val_acc')\n",
    "plt.title('Validating Accuracy skipgram CNN(2 Layers, 3 Layers)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df2 = pd.read_csv('./tweets2.csv', sep=',', header=0)\n",
    "tweet_list2 = tweets_df2['tweet']\n",
    "label_list2 = tweets_df2['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit_transform(label_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=1).split(word_seq_train, y_train)\n",
    "skf = StratifiedKFold(n_splits = 10)\n",
    "skf.get_n_splits(tweet_list2, label_list2)\n",
    "StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n",
    "for train_index, test_index in skf.split(tweet_list2, label_list2):\n",
    "    X_train, X_test = tweet_list2[train_index], tweet_list2[test_index]\n",
    "    Y_train, Y_test = label_list2[train_index], label_list2[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_list = []\n",
    "for sentence in tqdm(tweet_list2):\n",
    "    tokens = \" \".join(splitIntoStem(sentence)).split()\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    processed_list.append(\" \".join(filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"tweet\"] = processed_list\n",
    "df['doc_len'] = df['tweet'].apply(lambda words: len(words.split(\" \")))\n",
    "max_seq_len = np.round(df['doc_len'].mean() + df['doc_len'].std()).astype(int)\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train + X_test)\n",
    "word_seq_train2 = tokenizer.texts_to_sequences(X_train)\n",
    "word_seq_test2 = tokenizer.texts_to_sequences(X_test)\n",
    "word_index = tokenizer.word_index\n",
    "print(\"dictionary size: \", len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Binary to Real Mapping\n",
    "Num_filters = [32, 64, 128, 256]\n",
    "Architecture = [2, 3, 2, 2]\n",
    "Filter_size = [5, 7, 9, 11]\n",
    "# x -> np array BPSO Particle\n",
    "x = np.random.randint(2, size = 6)\n",
    "print(x)\n",
    "nf = int(\"\".join(map(str, x[0:2])), 2)\n",
    "ar = int(\"\".join(map(str, x[2:4])), 2)\n",
    "fs = int(\"\".join(map(str, x[4:6])), 2)\n",
    "num_filters = Num_filters[nf]\n",
    "architecture = Architecture[ar]\n",
    "filter_size = Filter_size[fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(num_filters, architecture, filter_size, word_seq_train, y_train, word_seq_test, y_val):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_seq_len, trainable=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    for i in range(architecture - 1):\n",
    "        model.add(Conv1D(num_filters, filter_size, padding='same', activation='relu', strides=1))\n",
    "        model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(num_filters, filter_size, activation='relu', padding='same'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    history = model.fit(word_seq_train, y_train, batch_size = batch_size, epochs = num_epochs, shuffle = True, validation_data = (word_seq_test, y_test))\n",
    "    score, acc = model.evaluate(word_seq_test, y_test)\n",
    "    print('Val accuracy:', acc)\n",
    "    return -acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_optimizer(x):\n",
    "    nf = int(\"\".join(map(str, x[0:2])), 2)\n",
    "    ar = int(\"\".join(map(str, x[2:4])), 2)\n",
    "    fs = int(\"\".join(map(str, x[4:6])), 2)\n",
    "    num_filters = Num_filters[nf]\n",
    "    architecture = Architecture[ar]\n",
    "    filter_size = Filter_size[fs]\n",
    "    return model(num_filters, architecture, filter_size, word_seq_train, y_train, word_seq_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class, which describes a single particle of a swarm.\n",
    "class Particle:\n",
    "    # D - dimension of a search space;\n",
    "    def __init__(self, D):\n",
    "        self.velocity = np.zeros(D)\n",
    "        self.coordinates = np.random.randint(2, size = D)\n",
    "        self.best_position = np.copy(self.coordinates)\n",
    "        self.best_score = float('inf') #fuck\n",
    "\n",
    "    # Update velocity based on particle's and group's best positions.\n",
    "    def __update_velocity(self, group_best_pos, w, c1, c2):\n",
    "        self.velocity = w * self.velocity + c1 * rand.random() * (self.best_position - self.coordinates) + c2 * rand.random() * (group_best_pos - self.coordinates)\n",
    "    \n",
    "    def compare_update(self, s):\n",
    "        if s < np.random.rand(1):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def sigmoid(x):\n",
    "        return 1.0 / (1.0 + np.exp(-(x)))\n",
    "    \n",
    "    # Update position of a particle.\n",
    "    def move(self, group_best_pos, w, c1, c2, fitness_function):\n",
    "        self.__update_velocity(group_best_pos, w, c1, c2)\n",
    "        self.coordinates = list(map(self.compare_update, list(map(self.sigmoid, self.velocity))))\n",
    "        current_score = fitness_function(self.coordinates)\n",
    "    # Evaluate Score\n",
    "    # Fitness Function to update current_score\n",
    "        \n",
    "        if current_score < self.best_score:\n",
    "            self.best_position = np.copy(self.coordinates)\n",
    "            self.best_score = current_score\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1.0 / (1.0 + np.exp(-(x)))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return (\n",
    "        'Current velocity = {0};\\nPosition: {1};\\nBest position so far: {2};\\nScore for the best position = {3}.\\n' \\\n",
    "        .format(self.velocity, self.coordinates, self.best_position, self.best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 6\n",
    "N = 6\n",
    "w = 0.7\n",
    "c1 = np.random.rand()\n",
    "c2 = np.random.rand()\n",
    "iter_num = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class, which describes our model, it's states of the optimization process.\n",
    "# Also contains methods for visualizing how the algorithm works.\n",
    "class Swarm:\n",
    "    # D - dimension of the search space;\n",
    "    # N - number of particles to generate;\n",
    "    # w, c1, c2 - model parameters;\n",
    "    # fitness_function - function of vector of parameters X to optimize;\n",
    "    # iter_num - maximum number of iterations.\n",
    "    def __init__(self, D, N, w, c1, c2, iter_num):\n",
    "        self.particles = [Particle(D) for _ in range(N)]\n",
    "        self.dimension = D\n",
    "        self.particles_num = N\n",
    "        self.w = w\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.iter_num = iter_num\n",
    "\n",
    "        # Setting random particle as group's initial best position\n",
    "        rnd_particle = self.particles[np.random.randint(N)]\n",
    "        self.group_best_position = np.copy(rnd_particle.coordinates)\n",
    "        self.group_best_score = self.fitness_function(rnd_particle.coordinates)\n",
    "        for p in self.particles:\n",
    "            print(p.__str__())\n",
    "\n",
    "    # Updates best group position and score (is called at every iteration).\n",
    "    def _update_group_best(self):\n",
    "        for p in self.particles:\n",
    "            if p.best_score < self.group_best_score:\n",
    "                self.group_best_score = p.best_score\n",
    "                self.group_best_position = np.copy(p.coordinates)\n",
    "\n",
    "    # Updates the positions of all the particles in the swarm.\n",
    "    def _move_all(self):\n",
    "        for p in self.particles:\n",
    "            p.move(self.group_best_position, self.w, self.c1, self.c2, self.fitness_function)\n",
    "\n",
    "    # Main loop of the algorithm.\n",
    "    def optimize(self):\n",
    "        i = 0\n",
    "        self._update_group_best()\n",
    "        while(i < self.iter_num):\n",
    "            self._move_all()\n",
    "            self._update_group_best()\n",
    "            i += 1\n",
    "            print(i,\" iteration grp_best: \",self.group_best_position)\n",
    "            for p in self.particles:\n",
    "                print(p.__str__())\n",
    "        return self.group_best_position\n",
    "    \n",
    "    def fitness_function(self, x):\n",
    "        return cnn_optimizer(x)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Best one:{0}'.format(self.group_best_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 12, 32)            67232     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 6, 32)             7200      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 3, 32)             7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_18 (Glo (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,322,420\n",
      "Trainable params: 82,820\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 3s - loss: 1.3977 - acc: 0.207 - ETA: 0s - loss: 1.3937 - acc: 0.222 - 3s 4ms/step - loss: 1.3912 - acc: 0.2331 - val_loss: 1.3848 - val_acc: 0.2715\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3791 - acc: 0.335 - ETA: 0s - loss: 1.3765 - acc: 0.345 - 0s 276us/step - loss: 1.3775 - acc: 0.3357 - val_loss: 1.3784 - val_acc: 0.2689\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3765 - acc: 0.289 - ETA: 0s - loss: 1.3682 - acc: 0.328 - 0s 257us/step - loss: 1.3654 - acc: 0.3385 - val_loss: 1.3684 - val_acc: 0.2820\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3596 - acc: 0.367 - ETA: 0s - loss: 1.3587 - acc: 0.343 - 0s 258us/step - loss: 1.3566 - acc: 0.3469 - val_loss: 1.3510 - val_acc: 0.3760\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3416 - acc: 0.367 - ETA: 0s - loss: 1.3385 - acc: 0.361 - 0s 257us/step - loss: 1.3264 - acc: 0.3722 - val_loss: 1.3206 - val_acc: 0.4726\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3111 - acc: 0.394 - ETA: 0s - loss: 1.3065 - acc: 0.384 - 0s 292us/step - loss: 1.3028 - acc: 0.3750 - val_loss: 1.2754 - val_acc: 0.5144\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2628 - acc: 0.437 - ETA: 0s - loss: 1.2678 - acc: 0.449 - 0s 264us/step - loss: 1.2597 - acc: 0.4508 - val_loss: 1.2203 - val_acc: 0.5483\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2190 - acc: 0.503 - ETA: 0s - loss: 1.2031 - acc: 0.517 - 0s 274us/step - loss: 1.1970 - acc: 0.5281 - val_loss: 1.1470 - val_acc: 0.6084\n",
      "383/383 [==============================] - ETA:  - 0s 172us/step\n",
      "Val accuracy: 0.6083550921619405\n",
      "Current velocity = [0. 0. 0. 0. 0. 0.];\n",
      "Position: [1 1 1 1 1 1];\n",
      "Best position so far: [1 1 1 1 1 1];\n",
      "Score for the best position = inf.\n",
      "\n",
      "Current velocity = [0. 0. 0. 0. 0. 0.];\n",
      "Position: [1 0 0 1 0 0];\n",
      "Best position so far: [1 0 0 1 0 0];\n",
      "Score for the best position = inf.\n",
      "\n",
      "Current velocity = [0. 0. 0. 0. 0. 0.];\n",
      "Position: [0 0 0 1 0 1];\n",
      "Best position so far: [0 0 0 1 0 1];\n",
      "Score for the best position = inf.\n",
      "\n",
      "Current velocity = [0. 0. 0. 0. 0. 0.];\n",
      "Position: [1 0 0 1 1 1];\n",
      "Best position so far: [1 0 0 1 1 1];\n",
      "Score for the best position = inf.\n",
      "\n",
      "Current velocity = [0. 0. 0. 0. 0. 0.];\n",
      "Position: [1 0 1 0 1 0];\n",
      "Best position so far: [1 0 1 0 1 0];\n",
      "Score for the best position = inf.\n",
      "\n",
      "Current velocity = [0. 0. 0. 0. 0. 0.];\n",
      "Position: [1 1 0 1 1 0];\n",
      "Best position so far: [1 1 0 1 1 0];\n",
      "Score for the best position = inf.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = Swarm(D, N = N, w = w, c1 = c1, c2 = c2, iter_num = iter_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 12, 64)            96064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 6, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 6, 64)             20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 3, 64)             20544     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_19 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,378,964\n",
      "Trainable params: 139,364\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 3s - loss: 1.3875 - acc: 0.257 - ETA: 0s - loss: 1.3873 - acc: 0.271 - 3s 4ms/step - loss: 1.3871 - acc: 0.2795 - val_loss: 1.3705 - val_acc: 0.3681\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3592 - acc: 0.312 - ETA: 0s - loss: 1.3541 - acc: 0.351 - 0s 322us/step - loss: 1.3558 - acc: 0.3455 - val_loss: 1.3452 - val_acc: 0.3995\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3606 - acc: 0.355 - ETA: 0s - loss: 1.3435 - acc: 0.365 - 0s 314us/step - loss: 1.3393 - acc: 0.3539 - val_loss: 1.3098 - val_acc: 0.4386\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3144 - acc: 0.386 - ETA: 0s - loss: 1.3063 - acc: 0.404 - 0s 314us/step - loss: 1.3006 - acc: 0.4213 - val_loss: 1.2542 - val_acc: 0.4856\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2829 - acc: 0.398 - ETA: 0s - loss: 1.2629 - acc: 0.433 - 0s 351us/step - loss: 1.2530 - acc: 0.4410 - val_loss: 1.1843 - val_acc: 0.5196\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.1998 - acc: 0.488 - ETA: 0s - loss: 1.1661 - acc: 0.531 - 0s 304us/step - loss: 1.1607 - acc: 0.5239 - val_loss: 1.0806 - val_acc: 0.5431\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.0946 - acc: 0.523 - ETA: 0s - loss: 1.0603 - acc: 0.556 - 0s 319us/step - loss: 1.0642 - acc: 0.5492 - val_loss: 0.9646 - val_acc: 0.5953\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.9627 - acc: 0.609 - ETA: 0s - loss: 0.9393 - acc: 0.628 - 0s 323us/step - loss: 0.9477 - acc: 0.6222 - val_loss: 0.8635 - val_acc: 0.6736\n",
      "383/383 [==============================] - ETA:  - ETA:  - 0s 277us/step\n",
      "Val accuracy: 0.6736292409523349\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 12, 256)           537856    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 6, 256)            459008    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_20 (Glo (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 2,244,820\n",
      "Trainable params: 1,005,220\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 3s - loss: 1.4136 - acc: 0.246 - ETA: 0s - loss: 1.3992 - acc: 0.279 - 3s 4ms/step - loss: 1.3889 - acc: 0.2809 - val_loss: 1.3410 - val_acc: 0.4204\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3503 - acc: 0.351 - ETA: 0s - loss: 1.3341 - acc: 0.330 - 1s 1ms/step - loss: 1.3262 - acc: 0.3497 - val_loss: 1.2589 - val_acc: 0.5405\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2399 - acc: 0.511 - ETA: 0s - loss: 1.2128 - acc: 0.566 - 1s 1ms/step - loss: 1.1906 - acc: 0.5772 - val_loss: 1.0815 - val_acc: 0.7206\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.0498 - acc: 0.636 - ETA: 0s - loss: 1.0287 - acc: 0.634 - 1s 1ms/step - loss: 0.9979 - acc: 0.6517 - val_loss: 0.8344 - val_acc: 0.7389\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.8077 - acc: 0.730 - ETA: 0s - loss: 0.8027 - acc: 0.724 - 1s 1ms/step - loss: 0.7828 - acc: 0.7303 - val_loss: 0.6671 - val_acc: 0.7781\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.6415 - acc: 0.765 - ETA: 0s - loss: 0.6319 - acc: 0.761 - 1s 1ms/step - loss: 0.6233 - acc: 0.7654 - val_loss: 0.6097 - val_acc: 0.7990\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.6368 - acc: 0.800 - ETA: 0s - loss: 0.5729 - acc: 0.796 - 1s 1ms/step - loss: 0.5156 - acc: 0.8160 - val_loss: 0.5029 - val_acc: 0.8198\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4273 - acc: 0.855 - ETA: 0s - loss: 0.4282 - acc: 0.853 - 1s 1ms/step - loss: 0.4190 - acc: 0.8483 - val_loss: 0.4936 - val_acc: 0.8329\n",
      "383/383 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - 0s 596us/step\n",
      "Val accuracy: 0.8328981703006256\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 12, 64)            211264    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 6, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 6, 64)             45120     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_21 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 32)                2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,498,196\n",
      "Trainable params: 258,596\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 3s - loss: 1.4133 - acc: 0.285 - ETA: 0s - loss: 1.4061 - acc: 0.265 - 3s 5ms/step - loss: 1.3982 - acc: 0.2795 - val_loss: 1.3676 - val_acc: 0.4204\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3545 - acc: 0.386 - ETA: 0s - loss: 1.3535 - acc: 0.369 - 1s 1ms/step - loss: 1.3515 - acc: 0.3806 - val_loss: 1.3324 - val_acc: 0.4830\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3323 - acc: 0.437 - ETA: 0s - loss: 1.3137 - acc: 0.482 - 1s 1ms/step - loss: 1.3059 - acc: 0.4817 - val_loss: 1.2665 - val_acc: 0.5744\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2684 - acc: 0.550 - ETA: 0s - loss: 1.2458 - acc: 0.539 - 2s 2ms/step - loss: 1.2378 - acc: 0.5449 - val_loss: 1.1606 - val_acc: 0.6789\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.1765 - acc: 0.593 - ETA: 0s - loss: 1.1540 - acc: 0.615 - 1s 2ms/step - loss: 1.1399 - acc: 0.6166 - val_loss: 1.0272 - val_acc: 0.7206\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.0662 - acc: 0.636 - ETA: 0s - loss: 1.0484 - acc: 0.632 - 1s 1ms/step - loss: 1.0328 - acc: 0.6348 - val_loss: 0.8953 - val_acc: 0.7493\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.9233 - acc: 0.687 - ETA: 0s - loss: 0.8989 - acc: 0.699 - 1s 1ms/step - loss: 0.8853 - acc: 0.7107 - val_loss: 0.7697 - val_acc: 0.7728\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.8252 - acc: 0.710 - ETA: 0s - loss: 0.8126 - acc: 0.722 - 1s 1ms/step - loss: 0.7923 - acc: 0.7346 - val_loss: 0.6651 - val_acc: 0.7911\n",
      "383/383 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 0s 1ms/step\n",
      "Val accuracy: 0.7911227133815656\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 12, 256)           845056    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 6, 256)            721152    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_22 (Glo (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 2,814,164\n",
      "Trainable params: 1,574,564\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 5s - loss: 1.4017 - acc: 0.246 - ETA: 1s - loss: 1.3824 - acc: 0.298 - 6s 9ms/step - loss: 1.3820 - acc: 0.2992 - val_loss: 1.3046 - val_acc: 0.4778\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 1.2822 - acc: 0.441 - ETA: 0s - loss: 1.2670 - acc: 0.472 - 4s 5ms/step - loss: 1.2496 - acc: 0.4831 - val_loss: 1.1145 - val_acc: 0.7102\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 1.0953 - acc: 0.668 - ETA: 0s - loss: 1.0591 - acc: 0.673 - 4s 5ms/step - loss: 1.0263 - acc: 0.6657 - val_loss: 0.8823 - val_acc: 0.6815\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 0.8657 - acc: 0.664 - ETA: 0s - loss: 0.7987 - acc: 0.724 - 4s 5ms/step - loss: 0.7554 - acc: 0.7514 - val_loss: 0.6455 - val_acc: 0.8042\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 0.6324 - acc: 0.828 - ETA: 0s - loss: 0.5764 - acc: 0.832 - 4s 5ms/step - loss: 0.5256 - acc: 0.8399 - val_loss: 0.5301 - val_acc: 0.8068\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 0.3998 - acc: 0.894 - ETA: 0s - loss: 0.3571 - acc: 0.904 - 4s 5ms/step - loss: 0.3882 - acc: 0.8848 - val_loss: 0.4986 - val_acc: 0.8381\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 0.3589 - acc: 0.890 - ETA: 0s - loss: 0.3423 - acc: 0.884 - 4s 5ms/step - loss: 0.3152 - acc: 0.8904 - val_loss: 0.5036 - val_acc: 0.8329\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 0.2346 - acc: 0.925 - ETA: 0s - loss: 0.2394 - acc: 0.925 - 5s 7ms/step - loss: 0.2383 - acc: 0.9199 - val_loss: 0.5107 - val_acc: 0.8407\n",
      "383/383 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 2s 4ms/step\n",
      "Val accuracy: 0.840731070807335\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 12, 256)           384256    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 6, 256)            327936    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_23 (Glo (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,960,148\n",
      "Trainable params: 720,548\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 4s - loss: 1.4016 - acc: 0.250 - ETA: 1s - loss: 1.3957 - acc: 0.255 - 4s 5ms/step - loss: 1.3845 - acc: 0.2542 - val_loss: 1.3234 - val_acc: 0.4151\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3242 - acc: 0.371 - ETA: 0s - loss: 1.3096 - acc: 0.375 - 1s 874us/step - loss: 1.3000 - acc: 0.3750 - val_loss: 1.2387 - val_acc: 0.4674\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2162 - acc: 0.492 - ETA: 0s - loss: 1.2036 - acc: 0.494 - 1s 851us/step - loss: 1.1857 - acc: 0.5309 - val_loss: 1.0699 - val_acc: 0.6580\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.0606 - acc: 0.664 - ETA: 0s - loss: 1.0258 - acc: 0.677 - 1s 854us/step - loss: 1.0055 - acc: 0.6910 - val_loss: 0.8631 - val_acc: 0.7572\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.8940 - acc: 0.746 - ETA: 0s - loss: 0.8334 - acc: 0.763 - 1s 880us/step - loss: 0.8077 - acc: 0.7654 - val_loss: 0.6734 - val_acc: 0.7781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.6572 - acc: 0.796 - ETA: 0s - loss: 0.6443 - acc: 0.804 - 1s 854us/step - loss: 0.6393 - acc: 0.8020 - val_loss: 0.5597 - val_acc: 0.7990\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.5740 - acc: 0.769 - ETA: 0s - loss: 0.5267 - acc: 0.802 - 1s 846us/step - loss: 0.5339 - acc: 0.8048 - val_loss: 0.4959 - val_acc: 0.8198\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4768 - acc: 0.824 - ETA: 0s - loss: 0.4209 - acc: 0.847 - 1s 1ms/step - loss: 0.4057 - acc: 0.8624 - val_loss: 0.4715 - val_acc: 0.8355\n",
      "383/383 [==============================] - ETA:  - ETA:  - ETA:  - 0s 457us/step\n",
      "Val accuracy: 0.8355091385368267\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_27 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 12, 256)           537856    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 6, 256)            459008    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_24 (Glo (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 2,244,820\n",
      "Trainable params: 1,005,220\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 4s - loss: 1.3875 - acc: 0.300 - ETA: 1s - loss: 1.3846 - acc: 0.279 - 4s 5ms/step - loss: 1.3768 - acc: 0.3006 - val_loss: 1.3388 - val_acc: 0.4386\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3220 - acc: 0.363 - ETA: 0s - loss: 1.3255 - acc: 0.343 - 1s 1ms/step - loss: 1.3083 - acc: 0.3736 - val_loss: 1.2264 - val_acc: 0.6031\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2058 - acc: 0.574 - ETA: 0s - loss: 1.1844 - acc: 0.587 - 1s 1ms/step - loss: 1.1650 - acc: 0.5843 - val_loss: 1.0486 - val_acc: 0.6188\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.0470 - acc: 0.574 - ETA: 0s - loss: 0.9893 - acc: 0.613 - 1s 1ms/step - loss: 0.9602 - acc: 0.6376 - val_loss: 0.8237 - val_acc: 0.7572\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.7825 - acc: 0.769 - ETA: 0s - loss: 0.7364 - acc: 0.769 - 1s 1ms/step - loss: 0.7287 - acc: 0.7753 - val_loss: 0.6478 - val_acc: 0.8146\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.6074 - acc: 0.828 - ETA: 0s - loss: 0.6062 - acc: 0.810 - 1s 1ms/step - loss: 0.5681 - acc: 0.8329 - val_loss: 0.5576 - val_acc: 0.8329\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.5261 - acc: 0.832 - ETA: 0s - loss: 0.4644 - acc: 0.849 - 1s 1ms/step - loss: 0.4428 - acc: 0.8525 - val_loss: 0.5264 - val_acc: 0.8486\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4001 - acc: 0.859 - ETA: 0s - loss: 0.3673 - acc: 0.880 - 1s 1ms/step - loss: 0.3485 - acc: 0.8904 - val_loss: 0.5212 - val_acc: 0.8355\n",
      "383/383 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - 0s 609us/step\n",
      "Val accuracy: 0.8355091363580669\n",
      "1  iteration grp_best:  [1 1 1 0 1 1]\n",
      "Current velocity = [-0.41655502 -0.41655502 -0.41655502  0.         -0.41655502  0.        ];\n",
      "Position: [0, 1, 0, 1, 0, 0];\n",
      "Best position so far: [0 1 0 1 0 0];\n",
      "Score for the best position = -0.6736292409523349.\n",
      "\n",
      "Current velocity = [-0.66318798  0.          0.          0.          0.          0.66318798];\n",
      "Position: [1, 1, 1, 1, 0, 1];\n",
      "Best position so far: [1 1 1 1 0 1];\n",
      "Score for the best position = -0.8328981703006256.\n",
      "\n",
      "Current velocity = [0. 0. 0. 0. 0. 0.];\n",
      "Position: [0, 1, 1, 1, 1, 1];\n",
      "Best position so far: [0 1 1 1 1 1];\n",
      "Score for the best position = -0.7911227133815656.\n",
      "\n",
      "Current velocity = [-0.71233661  0.          0.          0.         -0.71233661  0.        ];\n",
      "Position: [1, 1, 1, 0, 1, 1];\n",
      "Best position so far: [1 1 1 0 1 1];\n",
      "Score for the best position = -0.840731070807335.\n",
      "\n",
      "Current velocity = [-0.42208754  0.         -0.42208754  0.42208754 -0.42208754  0.42208754];\n",
      "Position: [1, 1, 0, 0, 0, 0];\n",
      "Best position so far: [1 1 0 0 0 0];\n",
      "Score for the best position = -0.8355091385368267.\n",
      "\n",
      "Current velocity = [-0.0596472 -0.0596472  0.         0.        -0.0596472  0.0596472];\n",
      "Position: [1, 1, 1, 1, 0, 1];\n",
      "Best position so far: [1 1 1 1 0 1];\n",
      "Score for the best position = -0.8355091363580669.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_28 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 12, 256)           384256    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 6, 256)            327936    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_25 (Glo (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,960,148\n",
      "Trainable params: 720,548\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 5s - loss: 1.4036 - acc: 0.238 - ETA: 1s - loss: 1.3831 - acc: 0.285 - 4s 6ms/step - loss: 1.3866 - acc: 0.2963 - val_loss: 1.3380 - val_acc: 0.4334\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3400 - acc: 0.312 - ETA: 0s - loss: 1.3281 - acc: 0.320 - 1s 1ms/step - loss: 1.3210 - acc: 0.3441 - val_loss: 1.2552 - val_acc: 0.5561\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2313 - acc: 0.507 - ETA: 0s - loss: 1.2270 - acc: 0.488 - 1s 918us/step - loss: 1.2145 - acc: 0.4916 - val_loss: 1.1207 - val_acc: 0.6423\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.1167 - acc: 0.550 - ETA: 0s - loss: 1.0910 - acc: 0.585 - 1s 961us/step - loss: 1.0660 - acc: 0.6053 - val_loss: 0.9356 - val_acc: 0.7493\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.9230 - acc: 0.730 - ETA: 0s - loss: 0.8948 - acc: 0.728 - 1s 1ms/step - loss: 0.8619 - acc: 0.7402 - val_loss: 0.7488 - val_acc: 0.7676\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.7194 - acc: 0.777 - ETA: 0s - loss: 0.6832 - acc: 0.785 - 1s 932us/step - loss: 0.6857 - acc: 0.7823 - val_loss: 0.6632 - val_acc: 0.7885\n",
      "Epoch 7/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - ETA: 0s - loss: 0.6607 - acc: 0.773 - ETA: 0s - loss: 0.6231 - acc: 0.793 - 1s 1ms/step - loss: 0.5894 - acc: 0.8048 - val_loss: 0.5598 - val_acc: 0.8120\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.5328 - acc: 0.820 - ETA: 0s - loss: 0.4853 - acc: 0.835 - 1s 950us/step - loss: 0.4734 - acc: 0.8371 - val_loss: 0.5109 - val_acc: 0.8355\n",
      "383/383 [==============================] - ETA:  - ETA:  - ETA:  - 0s 479us/step\n",
      "Val accuracy: 0.8355091362024412\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_29 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 12, 32)            48032     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 6, 32)             5152      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 3, 32)             5152      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_26 (Glo (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,299,124\n",
      "Trainable params: 59,524\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 4s - loss: 1.4002 - acc: 0.210 - ETA: 1s - loss: 1.3966 - acc: 0.226 - 3s 5ms/step - loss: 1.3943 - acc: 0.2289 - val_loss: 1.3781 - val_acc: 0.2846\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3877 - acc: 0.234 - ETA: 0s - loss: 1.3821 - acc: 0.253 - 0s 292us/step - loss: 1.3788 - acc: 0.2669 - val_loss: 1.3716 - val_acc: 0.2950\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3760 - acc: 0.273 - ETA: 0s - loss: 1.3635 - acc: 0.291 - 0s 255us/step - loss: 1.3653 - acc: 0.2978 - val_loss: 1.3639 - val_acc: 0.2820\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3579 - acc: 0.339 - ETA: 0s - loss: 1.3520 - acc: 0.326 - 0s 234us/step - loss: 1.3500 - acc: 0.3272 - val_loss: 1.3503 - val_acc: 0.2742\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3483 - acc: 0.335 - ETA: 0s - loss: 1.3456 - acc: 0.353 - 0s 277us/step - loss: 1.3398 - acc: 0.3624 - val_loss: 1.3305 - val_acc: 0.3211\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3337 - acc: 0.367 - 0s 197us/step - loss: 1.3202 - acc: 0.3764 - val_loss: 1.3034 - val_acc: 0.4360\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3001 - acc: 0.410 - ETA: 0s - loss: 1.3031 - acc: 0.414 - 0s 263us/step - loss: 1.2986 - acc: 0.4242 - val_loss: 1.2644 - val_acc: 0.4752\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2689 - acc: 0.449 - ETA: 0s - loss: 1.2564 - acc: 0.464 - 0s 269us/step - loss: 1.2531 - acc: 0.4747 - val_loss: 1.2144 - val_acc: 0.5614\n",
      "383/383 [==============================] - ETA:  - ETA:  - 0s 182us/step\n",
      "Val accuracy: 0.5613577032836237\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_30 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 12, 64)            172864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 6, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 6, 64)             36928     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_27 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,451,604\n",
      "Trainable params: 212,004\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 4s - loss: 1.3984 - acc: 0.293 - ETA: 1s - loss: 1.3942 - acc: 0.287 - 4s 5ms/step - loss: 1.3897 - acc: 0.2963 - val_loss: 1.3697 - val_acc: 0.2742\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3737 - acc: 0.281 - ETA: 0s - loss: 1.3549 - acc: 0.335 - 1s 1ms/step - loss: 1.3521 - acc: 0.3399 - val_loss: 1.3401 - val_acc: 0.3238\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3389 - acc: 0.355 - ETA: 0s - loss: 1.3264 - acc: 0.396 - 1s 1ms/step - loss: 1.3184 - acc: 0.4059 - val_loss: 1.2925 - val_acc: 0.3838\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3043 - acc: 0.406 - ETA: 0s - loss: 1.2721 - acc: 0.419 - 1s 1ms/step - loss: 1.2621 - acc: 0.4382 - val_loss: 1.2046 - val_acc: 0.5875\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2055 - acc: 0.496 - ETA: 0s - loss: 1.1890 - acc: 0.529 - 1s 1ms/step - loss: 1.1787 - acc: 0.5435 - val_loss: 1.0932 - val_acc: 0.7206\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.1318 - acc: 0.562 - ETA: 0s - loss: 1.1174 - acc: 0.572 - 1s 1ms/step - loss: 1.0874 - acc: 0.6081 - val_loss: 0.9698 - val_acc: 0.7572\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.9990 - acc: 0.683 - ETA: 0s - loss: 0.9966 - acc: 0.671 - 1s 1ms/step - loss: 0.9786 - acc: 0.6770 - val_loss: 0.8436 - val_acc: 0.7781\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.8611 - acc: 0.726 - ETA: 0s - loss: 0.8501 - acc: 0.732 - 1s 1ms/step - loss: 0.8568 - acc: 0.7247 - val_loss: 0.7277 - val_acc: 0.8042\n",
      "383/383 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 0s 1ms/step\n",
      "Val accuracy: 0.8041775436687718\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_31 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 12, 256)           845056    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 6, 256)            0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 6, 256)            721152    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 3, 256)            721152    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_28 (Glo (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 3,535,316\n",
      "Trainable params: 2,295,716\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 7s - loss: 1.3927 - acc: 0.269 - ETA: 2s - loss: 1.3830 - acc: 0.293 - 8s 11ms/step - loss: 1.3847 - acc: 0.2935 - val_loss: 1.3530 - val_acc: 0.2846\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 2s - loss: 1.3439 - acc: 0.316 - ETA: 0s - loss: 1.3342 - acc: 0.355 - 5s 7ms/step - loss: 1.3293 - acc: 0.3567 - val_loss: 1.2535 - val_acc: 0.4360\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 2s - loss: 1.2754 - acc: 0.406 - ETA: 0s - loss: 1.2365 - acc: 0.433 - 5s 7ms/step - loss: 1.1861 - acc: 0.4719 - val_loss: 1.0422 - val_acc: 0.5352\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 2s - loss: 0.9974 - acc: 0.539 - ETA: 0s - loss: 0.9282 - acc: 0.627 - 5s 7ms/step - loss: 0.9089 - acc: 0.6447 - val_loss: 0.7731 - val_acc: 0.7389\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 2s - loss: 0.7338 - acc: 0.753 - ETA: 0s - loss: 0.6833 - acc: 0.787 - 5s 7ms/step - loss: 0.6592 - acc: 0.7907 - val_loss: 0.6160 - val_acc: 0.8172\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 2s - loss: 0.5221 - acc: 0.832 - ETA: 1s - loss: 0.4742 - acc: 0.847 - 6s 8ms/step - loss: 0.4241 - acc: 0.8624 - val_loss: 0.6848 - val_acc: 0.8172\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 2s - loss: 0.4003 - acc: 0.859 - ETA: 1s - loss: 0.3529 - acc: 0.873 - 5s 7ms/step - loss: 0.3315 - acc: 0.8764 - val_loss: 0.6441 - val_acc: 0.8146\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 2s - loss: 0.2088 - acc: 0.941 - ETA: 0s - loss: 0.2265 - acc: 0.929 - 5s 7ms/step - loss: 0.2261 - acc: 0.9213 - val_loss: 0.6479 - val_acc: 0.8460\n",
      "383/383 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 2s 4ms/step\n",
      "Val accuracy: 0.8459530029222174\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_32 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 12, 32)            48032     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 6, 32)             5152      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_29 (Glo (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,293,972\n",
      "Trainable params: 54,372\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 5s - loss: 1.4307 - acc: 0.250 - ETA: 1s - loss: 1.4293 - acc: 0.232 - 4s 5ms/step - loss: 1.4266 - acc: 0.2261 - val_loss: 1.3964 - val_acc: 0.2272\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.4141 - acc: 0.234 - ETA: 0s - loss: 1.4074 - acc: 0.234 - 0s 275us/step - loss: 1.4036 - acc: 0.2374 - val_loss: 1.3786 - val_acc: 0.3446\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3880 - acc: 0.269 - ETA: 0s - loss: 1.3818 - acc: 0.300 - 0s 252us/step - loss: 1.3776 - acc: 0.3020 - val_loss: 1.3688 - val_acc: 0.4569\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3728 - acc: 0.347 - 0s 237us/step - loss: 1.3678 - acc: 0.3511 - val_loss: 1.3588 - val_acc: 0.5039\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3583 - acc: 0.398 - ETA: 0s - loss: 1.3543 - acc: 0.402 - 0s 307us/step - loss: 1.3549 - acc: 0.3933 - val_loss: 1.3463 - val_acc: 0.5117\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3531 - acc: 0.390 - ETA: 0s - loss: 1.3474 - acc: 0.392 - 0s 247us/step - loss: 1.3397 - acc: 0.4101 - val_loss: 1.3288 - val_acc: 0.5431\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3283 - acc: 0.449 - ETA: 0s - loss: 1.3190 - acc: 0.472 - 0s 251us/step - loss: 1.3205 - acc: 0.4537 - val_loss: 1.3031 - val_acc: 0.5927\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3000 - acc: 0.480 - ETA: 0s - loss: 1.2959 - acc: 0.476 - 0s 241us/step - loss: 1.2910 - acc: 0.4874 - val_loss: 1.2666 - val_acc: 0.6084\n",
      "383/383 [==============================] - ETA:  - ETA:  - 0s 213us/step\n",
      "Val accuracy: 0.6083550896719293\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_33 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 12, 256)           691456    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 6, 256)            590080    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_30 (Glo (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 2,529,492\n",
      "Trainable params: 1,289,892\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 6s - loss: 1.3857 - acc: 0.304 - ETA: 1s - loss: 1.3896 - acc: 0.285 - 7s 9ms/step - loss: 1.3838 - acc: 0.2921 - val_loss: 1.3266 - val_acc: 0.4151\n",
      "Epoch 2/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - ETA: 1s - loss: 1.3342 - acc: 0.371 - ETA: 0s - loss: 1.3096 - acc: 0.414 - 3s 4ms/step - loss: 1.2957 - acc: 0.4298 - val_loss: 1.1814 - val_acc: 0.5144\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 1.2117 - acc: 0.445 - ETA: 0s - loss: 1.1657 - acc: 0.484 - 3s 4ms/step - loss: 1.1240 - acc: 0.5253 - val_loss: 0.9699 - val_acc: 0.7206\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 0.9462 - acc: 0.695 - ETA: 0s - loss: 0.9077 - acc: 0.720 - 3s 4ms/step - loss: 0.8791 - acc: 0.7247 - val_loss: 0.7214 - val_acc: 0.7624\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 0.7172 - acc: 0.750 - ETA: 0s - loss: 0.6686 - acc: 0.771 - 3s 4ms/step - loss: 0.6318 - acc: 0.7865 - val_loss: 0.5850 - val_acc: 0.7963\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 0.4904 - acc: 0.851 - ETA: 0s - loss: 0.4952 - acc: 0.839 - 3s 4ms/step - loss: 0.4777 - acc: 0.8385 - val_loss: 0.5357 - val_acc: 0.8120\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 0.3636 - acc: 0.882 - ETA: 0s - loss: 0.3964 - acc: 0.867 - 3s 5ms/step - loss: 0.3805 - acc: 0.8736 - val_loss: 0.5349 - val_acc: 0.8303\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 0.2895 - acc: 0.914 - ETA: 0s - loss: 0.2978 - acc: 0.914 - 3s 4ms/step - loss: 0.2860 - acc: 0.9157 - val_loss: 0.5185 - val_acc: 0.8512\n",
      "383/383 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 3ms/step\n",
      "Val accuracy: 0.8511749350371\n",
      "2  iteration grp_best:  [1 1 1 1 1 0]\n",
      "Current velocity = [ 0.21329193 -0.29158851  0.21329193 -0.50488044  0.21329193  0.50488044];\n",
      "Position: [1, 1, 1, 1, 0, 0];\n",
      "Best position so far: [1 1 1 1 0 0];\n",
      "Score for the best position = -0.8355091362024412.\n",
      "\n",
      "Current velocity = [-0.46423159  0.          0.         -0.08505076  0.08505076  0.46423159];\n",
      "Position: [0, 0, 0, 1, 0, 0];\n",
      "Best position so far: [1 1 1 1 0 1];\n",
      "Score for the best position = -0.8328981703006256.\n",
      "\n",
      "Current velocity = [ 0.48024698  0.          0.         -0.48024698  0.          0.        ];\n",
      "Position: [0, 1, 1, 0, 1, 0];\n",
      "Best position so far: [0 1 1 0 1 0];\n",
      "Score for the best position = -0.8041775436687718.\n",
      "\n",
      "Current velocity = [-0.49863562  0.          0.          0.         -0.49863562  0.        ];\n",
      "Position: [1, 1, 0, 1, 1, 1];\n",
      "Best position so far: [1 1 0 1 1 1];\n",
      "Score for the best position = -0.8459530029222174.\n",
      "\n",
      "Current velocity = [-0.29546128  0.          0.07239094  0.29546128  0.07239094  0.6633135 ];\n",
      "Position: [0, 0, 1, 1, 0, 0];\n",
      "Best position so far: [1 1 0 0 0 0];\n",
      "Score for the best position = -0.8355091385368267.\n",
      "\n",
      "Current velocity = [-0.04175304 -0.04175304  0.         -0.28137326  0.23962021  0.04175304];\n",
      "Position: [1, 1, 1, 1, 1, 0];\n",
      "Best position so far: [1 1 1 1 1 0];\n",
      "Score for the best position = -0.8511749350371.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_34 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 12, 64)            134464    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 6, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 6, 64)             28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 3, 64)             28736     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_31 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,433,748\n",
      "Trainable params: 194,148\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 5s - loss: 1.4026 - acc: 0.316 - ETA: 1s - loss: 1.3963 - acc: 0.294 - 4s 6ms/step - loss: 1.3931 - acc: 0.2992 - val_loss: 1.3784 - val_acc: 0.2742\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3730 - acc: 0.312 - ETA: 0s - loss: 1.3739 - acc: 0.298 - 0s 398us/step - loss: 1.3703 - acc: 0.3174 - val_loss: 1.3657 - val_acc: 0.3342\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3595 - acc: 0.332 - ETA: 0s - loss: 1.3579 - acc: 0.318 - 0s 340us/step - loss: 1.3524 - acc: 0.3258 - val_loss: 1.3449 - val_acc: 0.3681\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3594 - acc: 0.293 - ETA: 0s - loss: 1.3308 - acc: 0.332 - 0s 392us/step - loss: 1.3210 - acc: 0.3399 - val_loss: 1.3096 - val_acc: 0.3473\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2836 - acc: 0.355 - ETA: 0s - loss: 1.2953 - acc: 0.328 - 0s 355us/step - loss: 1.2943 - acc: 0.3258 - val_loss: 1.2528 - val_acc: 0.4047\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2414 - acc: 0.398 - ETA: 0s - loss: 1.2326 - acc: 0.414 - 0s 429us/step - loss: 1.2283 - acc: 0.4143 - val_loss: 1.1786 - val_acc: 0.5248\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.1825 - acc: 0.496 - ETA: 0s - loss: 1.1593 - acc: 0.503 - 0s 384us/step - loss: 1.1557 - acc: 0.4817 - val_loss: 1.0649 - val_acc: 0.5352\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.0826 - acc: 0.453 - ETA: 0s - loss: 1.0596 - acc: 0.482 - 0s 381us/step - loss: 1.0486 - acc: 0.4874 - val_loss: 0.9582 - val_acc: 0.5927\n",
      "383/383 [==============================] - ETA:  - ETA:  - 0s 266us/step\n",
      "Val accuracy: 0.592689295817293\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_35 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 12, 64)            172864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 6, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 6, 64)             36928     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_90 (Conv1D)           (None, 3, 64)             36928     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_32 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 4)                 132       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 1,488,532\n",
      "Trainable params: 248,932\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 6s - loss: 1.3990 - acc: 0.207 - ETA: 1s - loss: 1.3898 - acc: 0.273 - 5s 6ms/step - loss: 1.3871 - acc: 0.2753 - val_loss: 1.3758 - val_acc: 0.3681\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3666 - acc: 0.355 - ETA: 0s - loss: 1.3676 - acc: 0.326 - 1s 1ms/step - loss: 1.3654 - acc: 0.3146 - val_loss: 1.3560 - val_acc: 0.4021\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3583 - acc: 0.339 - ETA: 0s - loss: 1.3457 - acc: 0.349 - 1s 1ms/step - loss: 1.3422 - acc: 0.3427 - val_loss: 1.3240 - val_acc: 0.3916\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3243 - acc: 0.359 - ETA: 0s - loss: 1.3117 - acc: 0.375 - 1s 1ms/step - loss: 1.3015 - acc: 0.4031 - val_loss: 1.2646 - val_acc: 0.4935\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2440 - acc: 0.472 - ETA: 0s - loss: 1.2314 - acc: 0.476 - 1s 1ms/step - loss: 1.2216 - acc: 0.4902 - val_loss: 1.1664 - val_acc: 0.5692\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.1840 - acc: 0.503 - ETA: 0s - loss: 1.1636 - acc: 0.523 - 1s 1ms/step - loss: 1.1353 - acc: 0.5520 - val_loss: 1.0328 - val_acc: 0.6762\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.0436 - acc: 0.582 - ETA: 0s - loss: 1.0138 - acc: 0.615 - 1s 1ms/step - loss: 0.9979 - acc: 0.6194 - val_loss: 0.8852 - val_acc: 0.7232\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.8866 - acc: 0.695 - ETA: 0s - loss: 0.8701 - acc: 0.685 - 1s 1ms/step - loss: 0.8799 - acc: 0.6756 - val_loss: 0.7512 - val_acc: 0.7598\n",
      "383/383 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 0s 1ms/step\n",
      "Val accuracy: 0.7597911231822818\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_36 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 12, 64)            134464    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 6, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 6, 64)             28736     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_33 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,405,012\n",
      "Trainable params: 165,412\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 5s - loss: 1.4025 - acc: 0.293 - ETA: 1s - loss: 1.4021 - acc: 0.271 - 4s 5ms/step - loss: 1.3994 - acc: 0.2767 - val_loss: 1.3703 - val_acc: 0.3081\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3664 - acc: 0.324 - ETA: 0s - loss: 1.3578 - acc: 0.345 - 0s 319us/step - loss: 1.3588 - acc: 0.3357 - val_loss: 1.3516 - val_acc: 0.4256\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3579 - acc: 0.347 - ETA: 0s - loss: 1.3397 - acc: 0.378 - 0s 329us/step - loss: 1.3374 - acc: 0.3792 - val_loss: 1.3165 - val_acc: 0.4726\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3102 - acc: 0.382 - ETA: 0s - loss: 1.3049 - acc: 0.398 - 0s 366us/step - loss: 1.2976 - acc: 0.4059 - val_loss: 1.2655 - val_acc: 0.4282\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2371 - acc: 0.480 - ETA: 0s - loss: 1.2532 - acc: 0.429 - 0s 310us/step - loss: 1.2429 - acc: 0.4354 - val_loss: 1.1927 - val_acc: 0.5822\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2053 - acc: 0.484 - ETA: 0s - loss: 1.1976 - acc: 0.529 - 0s 307us/step - loss: 1.1750 - acc: 0.5506 - val_loss: 1.1048 - val_acc: 0.7363\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.1115 - acc: 0.589 - ETA: 0s - loss: 1.1041 - acc: 0.607 - 0s 321us/step - loss: 1.0902 - acc: 0.5997 - val_loss: 0.9995 - val_acc: 0.7493\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.0301 - acc: 0.652 - ETA: 0s - loss: 0.9910 - acc: 0.666 - 0s 316us/step - loss: 0.9927 - acc: 0.6531 - val_loss: 0.8901 - val_acc: 0.7624\n",
      "383/383 [==============================] - ETA:  - ETA:  - 0s 269us/step\n",
      "Val accuracy: 0.7624020892397231\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_37 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 12, 128)           192128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 6, 128)            82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_34 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,518,036\n",
      "Trainable params: 278,436\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 5s - loss: 1.4168 - acc: 0.273 - ETA: 1s - loss: 1.3957 - acc: 0.300 - 4s 6ms/step - loss: 1.3886 - acc: 0.2978 - val_loss: 1.3630 - val_acc: 0.2846\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3606 - acc: 0.296 - ETA: 0s - loss: 1.3443 - acc: 0.341 - 0s 448us/step - loss: 1.3375 - acc: 0.3469 - val_loss: 1.3146 - val_acc: 0.3551\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2809 - acc: 0.425 - ETA: 0s - loss: 1.2837 - acc: 0.400 - 0s 442us/step - loss: 1.2766 - acc: 0.4228 - val_loss: 1.2276 - val_acc: 0.5405\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2242 - acc: 0.453 - ETA: 0s - loss: 1.2182 - acc: 0.488 - 0s 463us/step - loss: 1.1963 - acc: 0.5042 - val_loss: 1.1071 - val_acc: 0.6815\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.1103 - acc: 0.613 - ETA: 0s - loss: 1.0957 - acc: 0.609 - 0s 463us/step - loss: 1.0788 - acc: 0.6278 - val_loss: 0.9792 - val_acc: 0.7441\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.9892 - acc: 0.695 - ETA: 0s - loss: 0.9641 - acc: 0.687 - 0s 474us/step - loss: 0.9353 - acc: 0.6966 - val_loss: 0.8127 - val_acc: 0.7833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.8316 - acc: 0.714 - ETA: 0s - loss: 0.8123 - acc: 0.728 - 0s 487us/step - loss: 0.8018 - acc: 0.7233 - val_loss: 0.6888 - val_acc: 0.8016\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.6541 - acc: 0.785 - ETA: 0s - loss: 0.6741 - acc: 0.777 - 0s 460us/step - loss: 0.6658 - acc: 0.7795 - val_loss: 0.6017 - val_acc: 0.8120\n",
      "383/383 [==============================] - ETA:  - ETA:  - 0s 304us/step\n",
      "Val accuracy: 0.8120104440198554\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_38 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 12, 32)            86432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 6, 32)             9248      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_35 (Glo (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,336,468\n",
      "Trainable params: 96,868\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 5s - loss: 1.4053 - acc: 0.207 - ETA: 1s - loss: 1.3975 - acc: 0.222 - 4s 6ms/step - loss: 1.3914 - acc: 0.2360 - val_loss: 1.3694 - val_acc: 0.3185\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3655 - acc: 0.293 - ETA: 0s - loss: 1.3578 - acc: 0.306 - 0s 639us/step - loss: 1.3583 - acc: 0.3034 - val_loss: 1.3489 - val_acc: 0.4204\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3555 - acc: 0.332 - ETA: 0s - loss: 1.3467 - acc: 0.330 - 0s 611us/step - loss: 1.3356 - acc: 0.3624 - val_loss: 1.3213 - val_acc: 0.4413\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3053 - acc: 0.429 - ETA: 0s - loss: 1.2990 - acc: 0.447 - 0s 630us/step - loss: 1.3017 - acc: 0.4326 - val_loss: 1.2813 - val_acc: 0.5248\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2934 - acc: 0.421 - ETA: 0s - loss: 1.2748 - acc: 0.441 - 0s 633us/step - loss: 1.2723 - acc: 0.4494 - val_loss: 1.2358 - val_acc: 0.6893\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2503 - acc: 0.468 - ETA: 0s - loss: 1.2415 - acc: 0.484 - 0s 686us/step - loss: 1.2294 - acc: 0.5070 - val_loss: 1.1849 - val_acc: 0.7206\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.1874 - acc: 0.597 - ETA: 0s - loss: 1.1927 - acc: 0.570 - 0s 618us/step - loss: 1.1805 - acc: 0.5772 - val_loss: 1.1171 - val_acc: 0.7258\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.1142 - acc: 0.648 - ETA: 0s - loss: 1.1217 - acc: 0.617 - 0s 645us/step - loss: 1.1108 - acc: 0.6180 - val_loss: 1.0485 - val_acc: 0.7311\n",
      "383/383 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - 0s 671us/step\n",
      "Val accuracy: 0.7310704967060537\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_39 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 12, 256)           845056    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 6, 256)            721152    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_36 (Glo (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 2,814,164\n",
      "Trainable params: 1,574,564\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 7s - loss: 1.3816 - acc: 0.312 - ETA: 2s - loss: 1.3771 - acc: 0.304 - 7s 10ms/step - loss: 1.3758 - acc: 0.3104 - val_loss: 1.3279 - val_acc: 0.3368\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 1.3108 - acc: 0.367 - ETA: 0s - loss: 1.3005 - acc: 0.398 - 3s 5ms/step - loss: 1.2793 - acc: 0.4143 - val_loss: 1.1775 - val_acc: 0.5640\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 1.1462 - acc: 0.574 - ETA: 0s - loss: 1.1197 - acc: 0.576 - 3s 5ms/step - loss: 1.1023 - acc: 0.5913 - val_loss: 0.9422 - val_acc: 0.7441\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 0.8911 - acc: 0.750 - ETA: 0s - loss: 0.8779 - acc: 0.740 - 3s 5ms/step - loss: 0.8517 - acc: 0.7402 - val_loss: 0.6796 - val_acc: 0.7833\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 0.6598 - acc: 0.812 - ETA: 0s - loss: 0.6298 - acc: 0.810 - 3s 5ms/step - loss: 0.5913 - acc: 0.8216 - val_loss: 0.5477 - val_acc: 0.8042\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 0.4606 - acc: 0.835 - ETA: 0s - loss: 0.4370 - acc: 0.845 - 3s 5ms/step - loss: 0.4270 - acc: 0.8469 - val_loss: 0.4942 - val_acc: 0.8329\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 0.3716 - acc: 0.886 - ETA: 0s - loss: 0.3507 - acc: 0.898 - 4s 5ms/step - loss: 0.3429 - acc: 0.8989 - val_loss: 0.4993 - val_acc: 0.8355\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 1s - loss: 0.2740 - acc: 0.914 - ETA: 0s - loss: 0.2837 - acc: 0.904 - 5s 6ms/step - loss: 0.2621 - acc: 0.9143 - val_loss: 0.5069 - val_acc: 0.8486\n",
      "383/383 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 4ms/step\n",
      "Val accuracy: 0.8485639666452731\n",
      "3  iteration grp_best:  [1 1 1 1 1 0]\n",
      "Current velocity = [ 0.14930435 -0.20411196  0.14930435 -0.35341631  0.80992043  0.35341631];\n",
      "Position: [0, 1, 0, 1, 0, 1];\n",
      "Best position so far: [1 1 1 1 0 0];\n",
      "Score for the best position = -0.8355091362024412.\n",
      "\n",
      "Current velocity = [ 0.52207939  0.84704151  0.84704151 -0.05953553  0.38499095  0.84654821];\n",
      "Position: [0, 1, 0, 1, 1, 0];\n",
      "Best position so far: [1 1 1 1 0 1];\n",
      "Score for the best position = -0.8328981703006256.\n",
      "\n",
      "Current velocity = [0.86796388 0.         0.         0.19561811 0.         0.        ];\n",
      "Position: [0, 1, 0, 0, 0, 1];\n",
      "Best position so far: [0 1 1 0 1 0];\n",
      "Score for the best position = -0.8041775436687718.\n",
      "\n",
      "Current velocity = [-0.34904494  0.          0.07811531  0.         -0.34904494 -0.07811531];\n",
      "Position: [1, 0, 0, 0, 0, 0];\n",
      "Best position so far: [1 1 0 1 1 1];\n",
      "Score for the best position = -0.8459530029222174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current velocity = [ 0.95945847  1.16628137 -0.44872936 -0.29258012  0.71755201  0.46431945];\n",
      "Position: [0, 0, 1, 0, 1, 0];\n",
      "Best position so far: [1 1 0 0 0 0];\n",
      "Score for the best position = -0.8355091385368267.\n",
      "\n",
      "Current velocity = [-0.02922713 -0.02922713  0.         -0.19696128  0.16773415  0.02922713];\n",
      "Position: [1, 1, 0, 0, 1, 1];\n",
      "Best position so far: [1 1 1 1 1 0];\n",
      "Score for the best position = -0.8511749350371.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_40 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 12, 64)            134464    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 6, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 6, 64)             28736     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_37 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,405,012\n",
      "Trainable params: 165,412\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 6s - loss: 1.4088 - acc: 0.250 - ETA: 1s - loss: 1.3989 - acc: 0.273 - 4s 6ms/step - loss: 1.3923 - acc: 0.2753 - val_loss: 1.3661 - val_acc: 0.3681\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3666 - acc: 0.312 - ETA: 0s - loss: 1.3513 - acc: 0.337 - 0s 350us/step - loss: 1.3492 - acc: 0.3301 - val_loss: 1.3303 - val_acc: 0.4308\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3089 - acc: 0.406 - ETA: 0s - loss: 1.3036 - acc: 0.416 - 0s 359us/step - loss: 1.3032 - acc: 0.4171 - val_loss: 1.2722 - val_acc: 0.5039\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2558 - acc: 0.480 - ETA: 0s - loss: 1.2493 - acc: 0.478 - 0s 347us/step - loss: 1.2432 - acc: 0.4846 - val_loss: 1.1919 - val_acc: 0.5796\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.1783 - acc: 0.515 - ETA: 0s - loss: 1.1795 - acc: 0.513 - 0s 329us/step - loss: 1.1666 - acc: 0.5211 - val_loss: 1.0978 - val_acc: 0.5875\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.0873 - acc: 0.605 - ETA: 0s - loss: 1.0836 - acc: 0.613 - 0s 328us/step - loss: 1.0835 - acc: 0.5955 - val_loss: 1.0014 - val_acc: 0.6214\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.0072 - acc: 0.640 - ETA: 0s - loss: 0.9887 - acc: 0.640 - 0s 338us/step - loss: 0.9816 - acc: 0.6362 - val_loss: 0.9124 - val_acc: 0.6893\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.9695 - acc: 0.613 - ETA: 0s - loss: 0.9023 - acc: 0.660 - 0s 335us/step - loss: 0.9038 - acc: 0.6699 - val_loss: 0.8221 - val_acc: 0.7467\n",
      "383/383 [==============================] - ETA:  - ETA:  - 0s 294us/step\n",
      "Val accuracy: 0.7467362904050643\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_41 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 12, 128)           345728    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 6, 128)            147584    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 3, 128)            147584    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_38 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,884,756\n",
      "Trainable params: 645,156\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 8s - loss: 1.4000 - acc: 0.257 - ETA: 2s - loss: 1.3939 - acc: 0.259 - 7s 10ms/step - loss: 1.3879 - acc: 0.2837 - val_loss: 1.3669 - val_acc: 0.3943\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3739 - acc: 0.347 - ETA: 0s - loss: 1.3591 - acc: 0.367 - 2s 2ms/step - loss: 1.3589 - acc: 0.3413 - val_loss: 1.3247 - val_acc: 0.3995\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3116 - acc: 0.375 - ETA: 0s - loss: 1.3064 - acc: 0.392 - 2s 2ms/step - loss: 1.2944 - acc: 0.4087 - val_loss: 1.2166 - val_acc: 0.5561\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2244 - acc: 0.507 - ETA: 0s - loss: 1.1850 - acc: 0.556 - 2s 2ms/step - loss: 1.1599 - acc: 0.5829 - val_loss: 1.0162 - val_acc: 0.6997\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.0235 - acc: 0.625 - ETA: 0s - loss: 0.9771 - acc: 0.666 - 2s 2ms/step - loss: 0.9318 - acc: 0.6826 - val_loss: 0.7647 - val_acc: 0.7598\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.7517 - acc: 0.765 - ETA: 0s - loss: 0.7286 - acc: 0.767 - 2s 2ms/step - loss: 0.7051 - acc: 0.7612 - val_loss: 0.6064 - val_acc: 0.7807\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.6611 - acc: 0.796 - ETA: 0s - loss: 0.5684 - acc: 0.814 - 2s 2ms/step - loss: 0.5553 - acc: 0.8090 - val_loss: 0.5393 - val_acc: 0.8094\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4101 - acc: 0.894 - ETA: 0s - loss: 0.4177 - acc: 0.875 - 2s 2ms/step - loss: 0.3979 - acc: 0.8736 - val_loss: 0.5622 - val_acc: 0.8120\n",
      "383/383 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 2ms/step\n",
      "Val accuracy: 0.8120104416854699\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_42 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 12, 64)            134464    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 6, 64)             0         \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1d_105 (Conv1D)          (None, 6, 64)             28736     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_39 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,405,012\n",
      "Trainable params: 165,412\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 6s - loss: 1.4341 - acc: 0.222 - ETA: 1s - loss: 1.4190 - acc: 0.220 - 4s 6ms/step - loss: 1.4154 - acc: 0.2121 - val_loss: 1.3811 - val_acc: 0.3838\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3820 - acc: 0.308 - ETA: 0s - loss: 1.3813 - acc: 0.306 - 0s 321us/step - loss: 1.3793 - acc: 0.3216 - val_loss: 1.3704 - val_acc: 0.3368\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3759 - acc: 0.332 - ETA: 0s - loss: 1.3689 - acc: 0.337 - 0s 328us/step - loss: 1.3638 - acc: 0.3455 - val_loss: 1.3530 - val_acc: 0.3133\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3515 - acc: 0.371 - ETA: 0s - loss: 1.3459 - acc: 0.347 - 0s 336us/step - loss: 1.3418 - acc: 0.3680 - val_loss: 1.3271 - val_acc: 0.3943\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3361 - acc: 0.382 - ETA: 0s - loss: 1.3202 - acc: 0.402 - 0s 319us/step - loss: 1.3112 - acc: 0.4213 - val_loss: 1.2870 - val_acc: 0.5039\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2888 - acc: 0.433 - ETA: 0s - loss: 1.2729 - acc: 0.464 - 0s 327us/step - loss: 1.2635 - acc: 0.4719 - val_loss: 1.2261 - val_acc: 0.5561\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2077 - acc: 0.503 - ETA: 0s - loss: 1.2161 - acc: 0.490 - 0s 328us/step - loss: 1.2138 - acc: 0.4916 - val_loss: 1.1444 - val_acc: 0.5692\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.1643 - acc: 0.554 - ETA: 0s - loss: 1.1387 - acc: 0.556 - 0s 337us/step - loss: 1.1159 - acc: 0.5772 - val_loss: 1.0623 - val_acc: 0.6214\n",
      "383/383 [==============================] - ETA:  - ETA:  - 0s 252us/step\n",
      "Val accuracy: 0.6214099198035098\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_43 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 12, 32)            67232     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 6, 32)             7200      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 3, 32)             7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_40 (Glo (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,322,420\n",
      "Trainable params: 82,820\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 6s - loss: 1.3944 - acc: 0.238 - ETA: 1s - loss: 1.3945 - acc: 0.236 - 5s 7ms/step - loss: 1.3936 - acc: 0.2289 - val_loss: 1.3829 - val_acc: 0.3055\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3826 - acc: 0.265 - ETA: 0s - loss: 1.3787 - acc: 0.296 - 0s 276us/step - loss: 1.3789 - acc: 0.2935 - val_loss: 1.3747 - val_acc: 0.3211\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3690 - acc: 0.324 - ETA: 0s - loss: 1.3667 - acc: 0.320 - 0s 270us/step - loss: 1.3662 - acc: 0.3258 - val_loss: 1.3631 - val_acc: 0.2924\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3538 - acc: 0.367 - ETA: 0s - loss: 1.3564 - acc: 0.334 - 0s 256us/step - loss: 1.3493 - acc: 0.3413 - val_loss: 1.3453 - val_acc: 0.3029\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3203 - acc: 0.371 - ETA: 0s - loss: 1.3279 - acc: 0.361 - 0s 263us/step - loss: 1.3299 - acc: 0.3553 - val_loss: 1.3153 - val_acc: 0.3681\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2904 - acc: 0.386 - ETA: 0s - loss: 1.2899 - acc: 0.404 - 0s 257us/step - loss: 1.2935 - acc: 0.3961 - val_loss: 1.2707 - val_acc: 0.4909\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2654 - acc: 0.406 - ETA: 0s - loss: 1.2580 - acc: 0.425 - 0s 258us/step - loss: 1.2488 - acc: 0.4466 - val_loss: 1.2107 - val_acc: 0.5875\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2278 - acc: 0.480 - ETA: 0s - loss: 1.2127 - acc: 0.490 - 0s 281us/step - loss: 1.1999 - acc: 0.4986 - val_loss: 1.1367 - val_acc: 0.5927\n",
      "383/383 [==============================] - ETA:  - ETA:  - 0s 210us/step\n",
      "Val accuracy: 0.5926892959729188\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_44 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 12, 128)           345728    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 6, 128)            147584    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 3, 128)            147584    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_41 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,884,756\n",
      "Trainable params: 645,156\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - ETA: 7s - loss: 1.3996 - acc: 0.277 - ETA: 1s - loss: 1.3946 - acc: 0.283 - 6s 9ms/step - loss: 1.3891 - acc: 0.3034 - val_loss: 1.3761 - val_acc: 0.3760\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3687 - acc: 0.324 - ETA: 0s - loss: 1.3621 - acc: 0.328 - 2s 2ms/step - loss: 1.3681 - acc: 0.3132 - val_loss: 1.3366 - val_acc: 0.3159\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3185 - acc: 0.398 - ETA: 0s - loss: 1.3236 - acc: 0.349 - 2s 2ms/step - loss: 1.3157 - acc: 0.3624 - val_loss: 1.2412 - val_acc: 0.5379\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2433 - acc: 0.476 - ETA: 0s - loss: 1.2274 - acc: 0.470 - 2s 3ms/step - loss: 1.2122 - acc: 0.4789 - val_loss: 1.0794 - val_acc: 0.6580\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.0809 - acc: 0.562 - ETA: 0s - loss: 1.0596 - acc: 0.580 - 2s 3ms/step - loss: 1.0319 - acc: 0.6025 - val_loss: 0.8367 - val_acc: 0.7258\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.8659 - acc: 0.664 - ETA: 0s - loss: 0.8171 - acc: 0.695 - 2s 3ms/step - loss: 0.7983 - acc: 0.6966 - val_loss: 0.6809 - val_acc: 0.7572\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 7s - loss: 0.6278 - acc: 0.761 - ETA: 1s - loss: 0.6255 - acc: 0.755 - 6s 9ms/step - loss: 0.6156 - acc: 0.7865 - val_loss: 0.5862 - val_acc: 0.7963\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.5483 - acc: 0.808 - ETA: 0s - loss: 0.5077 - acc: 0.828 - 2s 3ms/step - loss: 0.5247 - acc: 0.8174 - val_loss: 0.5661 - val_acc: 0.8172\n",
      "383/383 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 2ms/step\n",
      "Val accuracy: 0.8172323739559781\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_45 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 12, 256)           384256    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 6, 256)            327936    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_42 (Glo (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,960,148\n",
      "Trainable params: 720,548\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 7s - loss: 1.4039 - acc: 0.289 - ETA: 1s - loss: 1.3915 - acc: 0.291 - 6s 8ms/step - loss: 1.3839 - acc: 0.3006 - val_loss: 1.3336 - val_acc: 0.4308\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3385 - acc: 0.390 - ETA: 0s - loss: 1.3095 - acc: 0.429 - 1s 936us/step - loss: 1.3029 - acc: 0.4213 - val_loss: 1.2516 - val_acc: 0.4543\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2290 - acc: 0.437 - ETA: 0s - loss: 1.2249 - acc: 0.445 - 1s 890us/step - loss: 1.2092 - acc: 0.4607 - val_loss: 1.1157 - val_acc: 0.5770\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.0937 - acc: 0.617 - ETA: 0s - loss: 1.0832 - acc: 0.574 - 1s 882us/step - loss: 1.0651 - acc: 0.5815 - val_loss: 0.9440 - val_acc: 0.6606\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.9445 - acc: 0.644 - ETA: 0s - loss: 0.8931 - acc: 0.701 - 1s 863us/step - loss: 0.8858 - acc: 0.7022 - val_loss: 0.7752 - val_acc: 0.7885\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.8067 - acc: 0.746 - ETA: 0s - loss: 0.7544 - acc: 0.771 - 1s 876us/step - loss: 0.7085 - acc: 0.7949 - val_loss: 0.6345 - val_acc: 0.8225\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.5396 - acc: 0.867 - ETA: 0s - loss: 0.5590 - acc: 0.849 - 1s 885us/step - loss: 0.5489 - acc: 0.8455 - val_loss: 0.5514 - val_acc: 0.8355\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4661 - acc: 0.832 - ETA: 0s - loss: 0.4514 - acc: 0.847 - 1s 884us/step - loss: 0.4458 - acc: 0.8581 - val_loss: 0.5104 - val_acc: 0.8486\n",
      "383/383 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - 0s 549us/step\n",
      "Val accuracy: 0.8485639664896475\n",
      "4  iteration grp_best:  [1 1 1 1 1 0]\n",
      "Current velocity = [ 0.71396618 -0.14287837  0.71396618 -0.24739142  0.82662195 -0.36206171];\n",
      "Position: [0, 1, 0, 0, 0, 1];\n",
      "Best position so far: [1 1 1 1 0 0];\n",
      "Score for the best position = -0.8355091362024412.\n",
      "\n",
      "Current velocity = [ 0.53633977  0.59292905  0.76381324 -0.04167487  0.10115629  0.76092111];\n",
      "Position: [1, 0, 0, 1, 1, 0];\n",
      "Best position so far: [1 1 1 1 0 1];\n",
      "Score for the best position = -0.8328981703006256.\n",
      "\n",
      "Current velocity = [ 1.09389182  0.          0.92760692  0.62324978  0.92760692 -0.92760692];\n",
      "Position: [0, 1, 0, 0, 0, 1];\n",
      "Best position so far: [0 1 1 0 1 0];\n",
      "Score for the best position = -0.8041775436687718.\n",
      "\n",
      "Current velocity = [-0.24433146  1.05608457  0.76602823  1.05608457  0.81175311  0.29005634];\n",
      "Position: [0, 0, 0, 1, 0, 1];\n",
      "Best position so far: [1 1 0 1 1 1];\n",
      "Score for the best position = -0.8459530029222174.\n",
      "\n",
      "Current velocity = [ 1.13752891  1.28230494 -0.36257068  0.21264176  0.45382628  0.32502361];\n",
      "Position: [1, 0, 0, 1, 1, 0];\n",
      "Best position so far: [1 1 0 0 0 0];\n",
      "Score for the best position = -0.8355091385368267.\n",
      "\n",
      "Current velocity = [-0.02045899 -0.02045899  0.36637386  0.22850096  0.1174139  -0.34591487];\n",
      "Position: [1, 1, 1, 1, 0, 0];\n",
      "Best position so far: [1 1 1 1 1 0];\n",
      "Score for the best position = -0.8511749350371.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_46 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 12, 64)            134464    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling (None, 6, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 6, 64)             28736     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_43 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,405,012\n",
      "Trainable params: 165,412\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - ETA: 6s - loss: 1.4441 - acc: 0.195 - ETA: 1s - loss: 1.4185 - acc: 0.228 - 5s 7ms/step - loss: 1.4081 - acc: 0.2472 - val_loss: 1.3690 - val_acc: 0.3838\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3719 - acc: 0.300 - ETA: 0s - loss: 1.3642 - acc: 0.310 - 0s 339us/step - loss: 1.3608 - acc: 0.3216 - val_loss: 1.3513 - val_acc: 0.4439\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3506 - acc: 0.332 - ETA: 0s - loss: 1.3381 - acc: 0.335 - 0s 326us/step - loss: 1.3406 - acc: 0.3385 - val_loss: 1.3266 - val_acc: 0.4621\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3223 - acc: 0.386 - ETA: 0s - loss: 1.3187 - acc: 0.382 - 0s 328us/step - loss: 1.3138 - acc: 0.3820 - val_loss: 1.2837 - val_acc: 0.4752\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2797 - acc: 0.398 - ETA: 0s - loss: 1.2674 - acc: 0.429 - 0s 346us/step - loss: 1.2647 - acc: 0.4368 - val_loss: 1.2208 - val_acc: 0.4935\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2042 - acc: 0.523 - ETA: 0s - loss: 1.2189 - acc: 0.484 - 0s 350us/step - loss: 1.2136 - acc: 0.4958 - val_loss: 1.1366 - val_acc: 0.5640\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.1410 - acc: 0.554 - ETA: 0s - loss: 1.1186 - acc: 0.589 - 0s 419us/step - loss: 1.1175 - acc: 0.5787 - val_loss: 1.0508 - val_acc: 0.6345\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.0755 - acc: 0.558 - ETA: 0s - loss: 1.0517 - acc: 0.601 - 0s 370us/step - loss: 1.0439 - acc: 0.6081 - val_loss: 0.9630 - val_acc: 0.6867\n",
      "383/383 [==============================] - ETA:  - ETA:  - 0s 333us/step\n",
      "Val accuracy: 0.6866840737295524\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_47 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 12, 64)            211264    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_73 (MaxPooling (None, 6, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 6, 64)             45120     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_44 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,498,196\n",
      "Trainable params: 258,596\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 7s - loss: 1.4083 - acc: 0.195 - ETA: 1s - loss: 1.3952 - acc: 0.244 - 6s 8ms/step - loss: 1.3873 - acc: 0.2654 - val_loss: 1.3676 - val_acc: 0.3629\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3750 - acc: 0.324 - ETA: 0s - loss: 1.3670 - acc: 0.341 - 1s 1ms/step - loss: 1.3638 - acc: 0.3553 - val_loss: 1.3423 - val_acc: 0.4047\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3225 - acc: 0.425 - ETA: 0s - loss: 1.3249 - acc: 0.388 - 1s 1ms/step - loss: 1.3224 - acc: 0.3975 - val_loss: 1.3034 - val_acc: 0.4569\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2854 - acc: 0.460 - ETA: 0s - loss: 1.2839 - acc: 0.429 - 1s 1ms/step - loss: 1.2774 - acc: 0.4466 - val_loss: 1.2394 - val_acc: 0.4674\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2337 - acc: 0.480 - ETA: 0s - loss: 1.2104 - acc: 0.517 - 1s 1ms/step - loss: 1.2083 - acc: 0.5112 - val_loss: 1.1340 - val_acc: 0.6658\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.1374 - acc: 0.589 - ETA: 0s - loss: 1.1139 - acc: 0.603 - 1s 1ms/step - loss: 1.1142 - acc: 0.5941 - val_loss: 1.0055 - val_acc: 0.7258\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.0147 - acc: 0.691 - ETA: 0s - loss: 0.9946 - acc: 0.691 - 1s 1ms/step - loss: 0.9802 - acc: 0.6812 - val_loss: 0.8775 - val_acc: 0.7493\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.8616 - acc: 0.761 - ETA: 0s - loss: 0.8726 - acc: 0.744 - 1s 1ms/step - loss: 0.8589 - acc: 0.7402 - val_loss: 0.7452 - val_acc: 0.7755\n",
      "383/383 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 0s 1ms/step\n",
      "Val accuracy: 0.7754569170369181\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_48 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 12, 32)            67232     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_74 (MaxPooling (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 6, 32)             7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_45 (Glo (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,315,220\n",
      "Trainable params: 75,620\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 7s - loss: 1.3887 - acc: 0.265 - ETA: 1s - loss: 1.3764 - acc: 0.291 - 5s 7ms/step - loss: 1.3797 - acc: 0.2795 - val_loss: 1.3580 - val_acc: 0.3342\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3659 - acc: 0.300 - ETA: 0s - loss: 1.3540 - acc: 0.335 - 0s 282us/step - loss: 1.3485 - acc: 0.3441 - val_loss: 1.3380 - val_acc: 0.4439\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3258 - acc: 0.371 - ETA: 0s - loss: 1.3288 - acc: 0.371 - 0s 272us/step - loss: 1.3341 - acc: 0.3610 - val_loss: 1.3103 - val_acc: 0.4491\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2808 - acc: 0.441 - ETA: 0s - loss: 1.2949 - acc: 0.404 - 0s 272us/step - loss: 1.2945 - acc: 0.4045 - val_loss: 1.2736 - val_acc: 0.4726\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2983 - acc: 0.394 - ETA: 0s - loss: 1.2768 - acc: 0.439 - 0s 259us/step - loss: 1.2585 - acc: 0.4579 - val_loss: 1.2233 - val_acc: 0.5091\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.1931 - acc: 0.531 - ETA: 0s - loss: 1.1907 - acc: 0.539 - 0s 264us/step - loss: 1.2030 - acc: 0.5197 - val_loss: 1.1662 - val_acc: 0.5457\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.1732 - acc: 0.531 - ETA: 0s - loss: 1.1642 - acc: 0.541 - 0s 281us/step - loss: 1.1550 - acc: 0.5548 - val_loss: 1.1043 - val_acc: 0.6240\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - ETA: 0s - loss: 1.1483 - acc: 0.519 - ETA: 0s - loss: 1.1213 - acc: 0.543 - 0s 272us/step - loss: 1.1071 - acc: 0.5772 - val_loss: 1.0436 - val_acc: 0.6867\n",
      "383/383 [==============================] - ETA:  - ETA:  - 0s 194us/step\n",
      "Val accuracy: 0.6866840735739267\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_49 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 12, 128)           268928    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_75 (MaxPooling (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 6, 128)            114816    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_46 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,627,604\n",
      "Trainable params: 388,004\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 7s - loss: 1.3985 - acc: 0.265 - ETA: 1s - loss: 1.3846 - acc: 0.281 - 6s 8ms/step - loss: 1.3801 - acc: 0.2907 - val_loss: 1.3406 - val_acc: 0.3107\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3234 - acc: 0.359 - ETA: 0s - loss: 1.3294 - acc: 0.347 - 0s 577us/step - loss: 1.3252 - acc: 0.3567 - val_loss: 1.2702 - val_acc: 0.5561\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2929 - acc: 0.425 - ETA: 0s - loss: 1.2645 - acc: 0.435 - 0s 577us/step - loss: 1.2468 - acc: 0.4579 - val_loss: 1.1626 - val_acc: 0.6266\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2200 - acc: 0.429 - ETA: 0s - loss: 1.1748 - acc: 0.507 - 0s 556us/step - loss: 1.1373 - acc: 0.5562 - val_loss: 1.0276 - val_acc: 0.7258\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.0711 - acc: 0.609 - ETA: 0s - loss: 1.0189 - acc: 0.640 - 0s 579us/step - loss: 0.9920 - acc: 0.6545 - val_loss: 0.8681 - val_acc: 0.7728\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.8052 - acc: 0.796 - ETA: 0s - loss: 0.8213 - acc: 0.765 - 0s 594us/step - loss: 0.8244 - acc: 0.7626 - val_loss: 0.7347 - val_acc: 0.8251\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.7365 - acc: 0.757 - ETA: 0s - loss: 0.7097 - acc: 0.793 - 0s 576us/step - loss: 0.6838 - acc: 0.8048 - val_loss: 0.6255 - val_acc: 0.8225\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.6292 - acc: 0.820 - ETA: 0s - loss: 0.5842 - acc: 0.834 - 0s 586us/step - loss: 0.5726 - acc: 0.8272 - val_loss: 0.5612 - val_acc: 0.8381\n",
      "383/383 [==============================] - ETA:  - ETA:  - ETA:  - 0s 429us/step\n",
      "Val accuracy: 0.8381201022598824\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_50 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 12, 32)            67232     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_76 (MaxPooling (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 6, 32)             7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_47 (Glo (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,315,220\n",
      "Trainable params: 75,620\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 8s - loss: 1.3922 - acc: 0.246 - ETA: 1s - loss: 1.3960 - acc: 0.236 - 6s 8ms/step - loss: 1.3938 - acc: 0.2444 - val_loss: 1.3766 - val_acc: 0.3133\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3731 - acc: 0.308 - ETA: 0s - loss: 1.3757 - acc: 0.310 - 0s 272us/step - loss: 1.3766 - acc: 0.3146 - val_loss: 1.3653 - val_acc: 0.3499\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3607 - acc: 0.324 - ETA: 0s - loss: 1.3590 - acc: 0.341 - 0s 289us/step - loss: 1.3653 - acc: 0.3132 - val_loss: 1.3530 - val_acc: 0.3812\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3514 - acc: 0.316 - ETA: 0s - loss: 1.3536 - acc: 0.316 - 0s 321us/step - loss: 1.3539 - acc: 0.3272 - val_loss: 1.3385 - val_acc: 0.3890\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3420 - acc: 0.308 - ETA: 0s - loss: 1.3290 - acc: 0.339 - 0s 298us/step - loss: 1.3292 - acc: 0.3413 - val_loss: 1.3202 - val_acc: 0.3995\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3261 - acc: 0.347 - ETA: 0s - loss: 1.3136 - acc: 0.371 - 0s 295us/step - loss: 1.3167 - acc: 0.3581 - val_loss: 1.2960 - val_acc: 0.4230\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2882 - acc: 0.429 - ETA: 0s - loss: 1.2885 - acc: 0.412 - 0s 279us/step - loss: 1.2874 - acc: 0.4143 - val_loss: 1.2615 - val_acc: 0.4465\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2561 - acc: 0.464 - ETA: 0s - loss: 1.2485 - acc: 0.466 - 0s 277us/step - loss: 1.2492 - acc: 0.4452 - val_loss: 1.2172 - val_acc: 0.4909\n",
      "383/383 [==============================] - ETA:  - ETA:  - 0s 231us/step\n",
      "Val accuracy: 0.49086161957708413\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_51 (Embedding)     (None, 12, 300)           1239600   \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 12, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 12, 64)            96064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_77 (MaxPooling (None, 6, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 6, 64)             20544     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_48 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_95 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,358,420\n",
      "Trainable params: 118,820\n",
      "Non-trainable params: 1,239,600\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 383 samples\n",
      "Epoch 1/8\n",
      "712/712 [==============================] - ETA: 8s - loss: 1.3820 - acc: 0.324 - ETA: 2s - loss: 1.3833 - acc: 0.314 - 6s 9ms/step - loss: 1.3795 - acc: 0.3272 - val_loss: 1.3673 - val_acc: 0.3629\n",
      "Epoch 2/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3659 - acc: 0.320 - ETA: 0s - loss: 1.3634 - acc: 0.320 - 0s 346us/step - loss: 1.3592 - acc: 0.3230 - val_loss: 1.3458 - val_acc: 0.4151\n",
      "Epoch 3/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3543 - acc: 0.300 - ETA: 0s - loss: 1.3313 - acc: 0.347 - 0s 329us/step - loss: 1.3350 - acc: 0.3455 - val_loss: 1.3211 - val_acc: 0.4256\n",
      "Epoch 4/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.3175 - acc: 0.339 - ETA: 0s - loss: 1.3080 - acc: 0.363 - 0s 349us/step - loss: 1.3036 - acc: 0.3792 - val_loss: 1.2842 - val_acc: 0.4804\n",
      "Epoch 5/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2816 - acc: 0.414 - ETA: 0s - loss: 1.2787 - acc: 0.425 - 0s 350us/step - loss: 1.2696 - acc: 0.4284 - val_loss: 1.2331 - val_acc: 0.5352\n",
      "Epoch 6/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.2288 - acc: 0.453 - ETA: 0s - loss: 1.2174 - acc: 0.480 - 0s 339us/step - loss: 1.2092 - acc: 0.4972 - val_loss: 1.1666 - val_acc: 0.6345\n",
      "Epoch 7/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.1798 - acc: 0.488 - ETA: 0s - loss: 1.1534 - acc: 0.531 - 0s 317us/step - loss: 1.1388 - acc: 0.5534 - val_loss: 1.0851 - val_acc: 0.6919\n",
      "Epoch 8/8\n",
      "712/712 [==============================] - ETA: 0s - loss: 1.0539 - acc: 0.628 - ETA: 0s - loss: 1.0556 - acc: 0.625 - 0s 352us/step - loss: 1.0595 - acc: 0.6081 - val_loss: 0.9891 - val_acc: 0.7154\n",
      "383/383 [==============================] - ETA:  - ETA:  - 0s 256us/step\n",
      "Val accuracy: 0.7154046977157692\n",
      "5  iteration grp_best:  [1 1 1 1 1 0]\n",
      "Current velocity = [ 1.03439957 -0.10001486  1.03439957  0.36144926  1.11057164 -0.78806645];\n",
      "Position: [0, 1, 0, 0, 0, 1];\n",
      "Best position so far: [1 1 1 1 0 0];\n",
      "Score for the best position = -0.8355091362024412.\n",
      "\n",
      "Current velocity = [ 0.37543784  0.88435762  1.00397655 -0.02917241 -0.05239696  0.65585114];\n",
      "Position: [0, 1, 1, 0, 1, 1];\n",
      "Best position so far: [1 1 1 1 0 1];\n",
      "Score for the best position = -0.8328981703006256.\n",
      "\n",
      "Current velocity = [ 1.47460904  0.          1.44770596  1.14515961  1.44770596 -1.44770596];\n",
      "Position: [0, 0, 0, 0, 0, 1];\n",
      "Best position so far: [0 1 1 0 1 0];\n",
      "Score for the best position = -0.8041775436687718.\n",
      "\n",
      "Current velocity = [ 0.86874654  1.77903775  1.11558367  0.7392592   1.60800573 -0.37632447];\n",
      "Position: [1, 0, 0, 0, 0, 1];\n",
      "Best position so far: [1 1 0 1 1 1];\n",
      "Score for the best position = -0.8459530029222174.\n",
      "\n",
      "Current velocity = [ 0.79627024  1.80277919  0.22919822 -0.2733188  -0.10448964  0.22751653];\n",
      "Position: [0, 0, 0, 0, 0, 1];\n",
      "Best position so far: [1 1 0 0 0 0];\n",
      "Score for the best position = -0.8355091385368267.\n",
      "\n",
      "Current velocity = [-0.01432129 -0.01432129  0.2564617   0.15995067  0.75208702 -0.24214041];\n",
      "Position: [0, 1, 1, 1, 0, 0];\n",
      "Best position so far: [1 1 1 1 1 0];\n",
      "Score for the best position = -0.8511749350371.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
